{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Questão 8:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 66.0/66.0MB downloaded\n"
     ]
    }
   ],
   "source": [
    "model = api.load(\"glove-wiki-gigaword-50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0 = \"Mark zuckerberg owns the facebook company\"\n",
    "s1 = \"Facebook company ceo is mark zuckerberg\"\n",
    "s2 = \"Microsoft is owned by Bill gates\"\n",
    "s3 = \"How to learn japanese\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_vec(sentence, model):\n",
    "    words = sentence.lower().split()\n",
    "    word_vecs = [model[word] for word in words if word in model]\n",
    "    if not word_vecs:\n",
    "        return None\n",
    "    return sum(word_vecs) / len(word_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula os vetores para cada frase\n",
    "vec0 = sentence_to_vec(s0, model)\n",
    "vec1 = sentence_to_vec(s1, model)\n",
    "vec2 = sentence_to_vec(s2, model)\n",
    "vec3 = sentence_to_vec(s3, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para calcular a similaridade cosseno\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    if vec1 is None or vec2 is None:\n",
    "        return None\n",
    "    return 1 - spatial.distance.cosine(vec1, vec2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similaridade entre s0 e s1: 0.9659231932518089\n",
      "Similaridade entre s0 e s2: 0.8659113507077242\n",
      "Similaridade entre s0 e s3: 0.5877998604663117\n",
      "Similaridade entre s1 e s2: 0.8596354984226938\n",
      "Similaridade entre s1 e s3: 0.5718077327907699\n",
      "Similaridade entre s2 e s3: 0.7226007143523474\n"
     ]
    }
   ],
   "source": [
    "print(\"Similaridade entre s0 e s1:\", cosine_similarity(vec0, vec1))\n",
    "print(\"Similaridade entre s0 e s2:\", cosine_similarity(vec0, vec2))\n",
    "print(\"Similaridade entre s0 e s3:\", cosine_similarity(vec0, vec3))\n",
    "print(\"Similaridade entre s1 e s2:\", cosine_similarity(vec1, vec2))\n",
    "print(\"Similaridade entre s1 e s3:\", cosine_similarity(vec1, vec3))\n",
    "print(\"Similaridade entre s2 e s3:\", cosine_similarity(vec2, vec3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Questão 9 (Exemplo prático):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Texto para tokenização\n",
    "text = \"Apple is looking at buying U.K. startup for $1 billion. This could be a big move!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenização de Sentenças:\n",
      "Apple is looking at buying U.K. startup for $1 billion.\n",
      "This could be a big move!\n",
      "\n",
      "Tokenização de Palavras:\n",
      "Apple\n",
      "is\n",
      "looking\n",
      "at\n",
      "buying\n",
      "U.K.\n",
      "startup\n",
      "for\n",
      "$\n",
      "1\n",
      "billion\n",
      ".\n",
      "This\n",
      "could\n",
      "be\n",
      "a\n",
      "big\n",
      "move\n",
      "!\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "\n",
    "# Tokenização de sentenças\n",
    "print(\"Tokenização de Sentenças:\")\n",
    "for sent in doc.sents:\n",
    "    print(sent.text)\n",
    "\n",
    "# Tokenização de palavras\n",
    "print(\"\\nTokenização de Palavras:\")\n",
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explicação do Código\n",
    "\n",
    "- **Carregar o Modelo**: `spacy.load('en_core_web_sm')` carrega o modelo de linguagem que você baixou. Este modelo contém o pipeline de processamento necessário, incluindo a tokenização.\n",
    "- **Processar o Texto**: `nlp(text)` processa o texto e aplica o modelo, o que inclui a divisão do texto em tokens e sentenças.\n",
    "- **Tokenização de Sentenças**: `doc.sents` é um gerador que itera sobre as sentenças tokenizadas do documento.\n",
    "- **Tokenização de Palavras**: Ao iterar sobre `doc`, você acessa cada token individualmente.\n",
    "\n",
    "Este exemplo fornece uma visão de como realizar a tokenização utilizando a biblioteca `spaCy`, que é adequada tanto para aplicações acadêmicas quanto comerciais devido à sua robustez e eficiência."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Questão 11:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "from scipy import spatial\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = api.load(\"glove-wiki-gigaword-50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "frases = [\n",
    "    \"Mark Zuckerberg is the founder of Facebook.\",\n",
    "    \"Facebook is one of the largest social media platforms.\",\n",
    "    \"Bill Gates co-founded Microsoft.\",\n",
    "    \"Microsoft develops software products like Windows and Office.\",\n",
    "    \"Steve Jobs was the co-founder of Apple.\",\n",
    "    \"Apple is known for its iPhones and Mac computers.\",\n",
    "    \"Elon Musk is the CEO of SpaceX and Tesla.\",\n",
    "    \"Tesla is a leader in electric vehicles.\",\n",
    "    \"Google is a major player in the tech industry.\",\n",
    "    \"Amazon is a giant in e-commerce and cloud computing.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frase_para_vetor(frase):\n",
    "    words = [word for word in frase.lower().split() if word in model]\n",
    "    if words:\n",
    "        return np.mean([model[word] for word in words], axis=0)\n",
    "    else:\n",
    "        return np.zeros(50)\n",
    "\n",
    "def buscar_frases(palavra):\n",
    "    palavra_vec = model[palavra]\n",
    "    frase_vecs = [(frase, frase_para_vetor(frase)) for frase in frases]\n",
    "    similaridades = [(frase, 1 - spatial.distance.cosine(palavra_vec, vec)) for frase, vec in frase_vecs if np.any(vec)]\n",
    "    similaridades.sort(key=lambda x: x[1], reverse=True)\n",
    "    return similaridades[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frase: Apple is known for its iPhones and Mac computers. - Similaridade: 0.7754\n",
      "Frase: Microsoft develops software products like Windows and Office. - Similaridade: 0.7601\n",
      "Frase: Amazon is a giant in e-commerce and cloud computing. - Similaridade: 0.6364\n",
      "Frase: Tesla is a leader in electric vehicles. - Similaridade: 0.5575\n",
      "Frase: Elon Musk is the CEO of SpaceX and Tesla. - Similaridade: 0.5499\n"
     ]
    }
   ],
   "source": [
    "resultados = buscar_frases('apple')\n",
    "for frase, sim in resultados:\n",
    "    print(f'Frase: {frase} - Similaridade: {sim:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Análise das Saídas\n",
    "\n",
    "1. **Alta Similaridade com Frases Relevantes**:\n",
    "   - A frase \"Apple is known for its iPhones and Mac computers.\" tem a maior similaridade (0.7754). Isso faz sentido, pois essa frase contém a palavra-chave \"Apple\" e fala diretamente sobre produtos da Apple, indicando uma alta relevância contextual e semântica.\n",
    "   \n",
    "2. **Frases Relacionadas à Tecnologia e Inovação**:\n",
    "   - As frases sobre \"Microsoft\", \"Amazon\", \"Tesla\", e \"Elon Musk\" também aparecem na lista, embora com similaridades menores. Isso pode ser devido à associação geral entre essas empresas e o setor de tecnologia e inovação, que também é o contexto principal para \"Apple\". Essa é uma indicação de que o modelo GloVe não apenas captura a similaridade direta de palavras, mas também associações contextuais mais amplas.\n",
    "   \n",
    "3. **Diversidade nos Resultados**:\n",
    "   - A inclusão de frases relacionadas a diferentes empresas de tecnologia sugere que o modelo consegue capturar e entender o campo semântico associado à palavra \"apple\" no contexto de empresas líderes de tecnologia. Isso demonstra a utilidade do modelo GloVe em tarefas de recuperação de informações onde o contexto e as associações gerais são importantes.\n",
    "\n",
    "### Implicações Práticas\n",
    "\n",
    "- **Recuperação de Informações**: A habilidade de associar \"apple\" com outras empresas de tecnologia mostra que tal sistema pode ser usado para recuperação de informações ou sistemas de recomendação onde entender o contexto e as relações semânticas é crucial.\n",
    "  \n",
    "- **Sistemas de Recomendação**: Este tipo de modelo pode ser aplicado em sistemas de recomendação para sugerir conteúdos relacionados, notícias, ou produtos baseados em palavras-chave ou tópicos de interesse.\n",
    "\n",
    "- **Análise Semântica**: O uso de modelos de embeddings como GloVe é ideal para análises que requerem uma compreensão do espaço semântico das palavras, como em análises de sentimentos, agrupamento de textos ou classificação.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
